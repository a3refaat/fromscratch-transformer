# FromScratch-Transformer 

Paying my respects. 

---

##  Features

- Layered architecture: Input, Hidden, Output, BatchNorm
- Activation functions: ReLU, Sigmoid, Softmax
- Loss functions: Cross-Entropy, MSE
- Batch training with gradient descent
- Optimizers: SGD, Momentum, Adam
- Learning Curve plots
- Modular design (clean, extensible Python classes)
- Glorot and He initialization
- Recursive backpropagation
- MNIST demo included
